{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0365be-7486-494b-881b-8824bc3801a6",
   "metadata": {},
   "source": [
    "# Beet segmentation (optional) data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8cb0c1-9179-4941-bf8c-090a5f2ecb26",
   "metadata": {},
   "source": [
    "Date: 11.01.2024  \n",
    "Authors: Gustav Schimmer & Philipp Friedrich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e7430-5bee-4568-b8fa-b4c5b420b365",
   "metadata": {},
   "source": [
    "**This notebook is purposed for data preparation before training a YOLOv6 algorithm in detecting sugar beet plants on images.**  \n",
    "  \n",
    "  \n",
    "Major steps are:\n",
    "- Downsampling and Resizing of images\n",
    "- Create custom dataset with labeled data\n",
    "\n",
    "Before we train our model, we need to prepare a proper dataset containing images for testing and validation in the right resolution and size. This notebook is a suggestion on how to generate such a dataset. In case you dont want to generate and use own training data, we provided a ready to use example dataset, which can be found in the data section of this project (example_dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee60dc8-38b6-4767-b2d7-3b6401dc9efc",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7824674a-9d8c-4592-825b-0aa0c6140d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d42d93-75f6-4a14-8cdb-c152c31cf807",
   "metadata": {},
   "source": [
    "## Data preparation: Downsampling & Resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5248715-252e-47e8-80f7-1e2ad00942aa",
   "metadata": {},
   "source": [
    "Before creation of a custom dataset, data needs to be resampled to a lower resolution to minimize needed computation power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ef7a1-5d32-49a6-ba26-b5458421a57d",
   "metadata": {},
   "source": [
    "#### Define data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c250c711-0018-4d95-afb5-62015d6cc900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data path\n",
    "input_folder = r'..\\beet-segmentation\\data\\20230514\\field_1'\n",
    "\n",
    "# Output data path\n",
    "output_folder = r'..\\beet-segmentation\\data\\20230514\\field_1_test_img'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb1d39-5555-47cb-86d2-54b0a415d15b",
   "metadata": {},
   "source": [
    "#### Write function to resample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e342dad5-d8f7-4df3-82a3-e64bfc30113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function to resample images to taret width and height\n",
    "def crop_and_resize_image(input_path, output_folder, square_size, target_width, target_height):\n",
    "    image = cv2.imread(input_path)\n",
    "    if image is not None:\n",
    "        # Verkleinere das Bild auf die Zielgröße\n",
    "        image = cv2.resize(image, (target_width, target_height))\n",
    "        # Zuschneiden in 256x256 Quadraten\n",
    "        for y in range(0, target_height - square_size + 1, square_size):\n",
    "            for x in range(0, target_width - square_size + 1, square_size):\n",
    "                square = image[y:y + square_size, x:x + square_size]\n",
    "                # Speichere das Quadrat mit einem fortlaufenden Index\n",
    "                output_path = os.path.join(output_folder, f\"{os.path.splitext(os.path.basename(input_path))[0]}_{y // square_size * (target_width // square_size) + x // square_size}.jpg\")\n",
    "                cv2.imwrite(output_path, square)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c589e3f-6133-4cf5-8de9-545b6fbe6af8",
   "metadata": {},
   "source": [
    "#### Image resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9524b-9f02-4216-b93b-2e7caf20810e",
   "metadata": {},
   "source": [
    "As we tried different image resolutions, for our images a resolution of 1500x2000 yields a good compromise between results and computation power. This relates to a Ground Sampling Distance (GSD) of 0.1 centimeters. To make the images usable for YOLOv6 algorithm we additionally need to resize them to a squared size, for wich we use 500x500 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3129e1f3-0c4b-43d2-8799-05afa955fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target image width and height\n",
    "target_width, target_height = 1500, 2000\n",
    "square_size = 500\n",
    "\n",
    "# Erstelle den Ausgabeordner, wenn er nicht existiert\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Durchlaufe alle Bilder im Eingabeordner\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        crop_and_resize_image(input_path, output_folder, square_size, target_width, target_height)\n",
    "\n",
    "print(\"Image resampling done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d28ff22-f872-4796-9030-092cabf96e84",
   "metadata": {},
   "source": [
    "## Create training lables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e6822-7a42-4652-829e-ced5807b8c3f",
   "metadata": {},
   "source": [
    "To train the algorithm training data consisting of annotations are necessary. This often is cost and time intensive. Some of the open source tools available online are:\n",
    "\n",
    "- https://roboflow.com/annotate?ref=blog.roboflow.com\n",
    "\n",
    "- https://blog.roboflow.com/cvat/\n",
    "\n",
    "- https://blog.roboflow.com/labelimg/\n",
    "\n",
    "- https://www.makesense.ai/\n",
    "\n",
    "In our case we need to create lables for the single sugar beet plants on the images. If you want to create your own lables for your own images you can use one of the above mentioned tools. We recomend using Make Sense AI as it is open source and supports Yolo output file formats. \n",
    "\n",
    "\n",
    "One image should corresponds to one label file, and the label format example is presented as below.\n",
    "\n",
    "```json\n",
    "# class_id center_x center_y bbox_width bbox_height\n",
    "0 0.300926 0.617063 0.601852 0.765873\n",
    "1 0.575 0.319531 0.4 0.551562\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d36f9e-85a3-4827-b91c-4b8161d3652d",
   "metadata": {},
   "source": [
    "## Create custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17851fb6-64b1-46d9-8869-b715b79ff8e8",
   "metadata": {},
   "source": [
    "The generated images and lables should be devided into training and validation data (approximately 80:20). Organize your directory of the custom dataset as follows:\n",
    "\n",
    "```shell\n",
    "custom_dataset\n",
    "├── images\n",
    "│   ├── train\n",
    "│   │   ├── train0.jpg\n",
    "│   │   └── train1.jpg\n",
    "│   ├── val\n",
    "│   │   ├── val0.jpg\n",
    "│   │   └── val1.jpg\n",
    "│   └── test\n",
    "│       ├── test0.jpg\n",
    "│       └── test1.jpg\n",
    "└── labels\n",
    "    ├── train\n",
    "    │   ├── train0.txt\n",
    "    │   └── train1.txt\n",
    "    ├── val\n",
    "    │   ├── val0.txt\n",
    "    │   └── val1.txt\n",
    "    └── test\n",
    "        ├── test0.txt\n",
    "        └── test1.txt\n",
    "```\n",
    "\n",
    "Your custom datset is now ready to use. You can continue with model training in this [Jupyter Notebook](beet_segmentation_model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5e4b4-dc4f-49c0-8956-b660c06722cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
